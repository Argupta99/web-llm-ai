# ğŸ§  WebLLM Chatbot with LLaMA-3

This is a local AI chatbot built using [MLC WebLLM](https://mlc.ai/web-llm/) that runs entirely in the browser with **no internet or server connection required**. It uses **Metaâ€™s LLaMA-3 model**, loaded and executed via WebGPU.

> ğŸ’¡ Note: This app runs only on **desktop browsers that support WebGPU** (e.g., Chrome 113+ or Edge 113+). It will **not work** on mobile devices or unsupported systems.

---

## ğŸš€ Features

- Interactive chat interface like ChatGPT
- Uses the open-source LLaMA 3 8B model locally
- No API keys or server calls
- React-based frontend UI
- Real-time model loading and response handling via WebGPU

---

## ğŸ–¥ï¸ Local Setup

To run the project locally:

bash
# Clone the repository
git clone https://github.com/Argupta99/web-llm-ai

# Navigate into the project folder
cd your-repo-name

# Install dependencies
npm install

# Start the development server
npm run dev